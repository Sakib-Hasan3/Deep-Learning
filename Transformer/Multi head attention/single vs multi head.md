
---

# üî∑ 1Ô∏è‚É£ Single Head ‡¶Ü‡¶∏‡¶≤‡ßá ‡¶ï‡ßÄ ‡¶ï‡¶∞‡¶õ‡ßá?

Single-head attention:

$$
Z = \mathrm{softmax}\left(\frac{QK^{\top}}{\sqrt{d_k}}\right)V
$$

‡¶è‡¶ñ‡¶æ‡¶®‡ßá:

* ‡¶è‡¶ï‡¶ü‡¶æ‡¶á projection space
* ‡¶è‡¶ï‡¶ü‡¶æ‡¶á similarity metric
* ‡¶è‡¶ï‡¶ü‡¶æ‡¶á attention distribution

‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé:

> Model ‡¶è‡¶ï‡¶ü‡¶ø ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ similarity structure ‡¶∂‡¶ø‡¶ñ‡¶õ‡ßá‡•§

---

# üî∑ 2Ô∏è‚É£ Multi-Head ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ?

Multi-head ‡¶è:

$$
\mathrm{head}_i = \mathrm{Attention}(QW_i^Q,\; KW_i^K,\; VW_i^V)
$$

‡¶§‡¶æ‡¶∞‡¶™‡¶∞:

$$
\mathrm{MultiHead} = \mathrm{Concat}(\mathrm{head}_1,\dots,\mathrm{head}_h)W_O
$$

‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø head:

* ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ projection matrix
* ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ subspace
* ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ similarity metric

---

# üî∑ 3Ô∏è‚É£ Linear Algebra Perspective

‡¶ß‡¶∞‡¶ø:

Single-head projection:

$$
Q = X W_Q
$$

‡¶è‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡¶ø linear transformation‡•§

‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ multi-head ‡¶è:

$$
Q_i = X W_i^Q
$$

‡¶Æ‡¶æ‡¶®‡ßá:

* ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø head ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ basis ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶õ‡ßá
* ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ feature subspace-‡¶è ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶õ‡ßá

‡¶è‡¶ü‡¶æ equivalent:


$$
X \rightarrow [\mathrm{Subspace}_1,\; \mathrm{Subspace}_2,\; \dots,\; \mathrm{Subspace}_h]
$$

---

# üî∑ 4Ô∏è‚É£ Expressiveness Proof (Conceptual)

Single head attention:

$$
Z = A V
$$

‡¶è‡¶ü‡¶æ essentially:

> One weighted average over one feature space


Multi-head attention:

$$
Z = [A_1V_1,\; A_2V_2,\; \dots,\; A_hV_h]W_O
$$

‡¶è‡¶ü‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá:

> Multiple independent weighted averages ‚Üí ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ learnable mixing

‡¶è‡¶ü‡¶æ mathematically equivalent ‡¶®‡ßü single-head ‡¶è‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá‡•§

---

# üî∑ 5Ô∏è‚É£ ‡¶ï‡ßá‡¶® Equivalent ‡¶®‡¶æ?

‡¶ß‡¶∞‡¶ø:

Single-head dimension = 64

Multi-head:

* 4 head √ó 16 dimension

‡¶è‡¶ó‡ßÅ‡¶≤‡ßã ‡¶è‡¶ï‡¶á ‡¶Æ‡ßã‡¶ü dimension ‡¶π‡¶≤‡ßá‡¶ì:

* ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø head ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ projection ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶õ‡ßá
* Attention weights ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ

‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé:


$$
\mathrm{softmax}(Q_1K_1^{\top}) \neq \mathrm{softmax}(Q_2K_2^{\top})
$$

‡¶è‡¶ó‡ßÅ‡¶≤‡ßã combine ‡¶ï‡¶∞‡¶≤‡ßá nonlinear composition ‡¶§‡ßà‡¶∞‡¶ø ‡¶π‡ßü‡•§

Single-head ‡¶è‡¶ü‡¶æ replicate ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‡¶®‡¶æ unless:

* dimension massively ‡¶¨‡¶æ‡ßú‡¶æ‡¶®‡ßã ‡¶π‡ßü

---

# üî∑ 6Ô∏è‚É£ Nonlinear Mixing Advantage

Multi-head:


$$
\mathrm{Concat}(\mathrm{head}_1,\; \mathrm{head}_2)W_O
$$

‡¶è‡¶ñ‡¶æ‡¶®‡ßá:

* ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá independent nonlinear attention
* ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ linear combination

‡¶è‡¶ü‡¶æ effectively deeper function class ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá‡•§

---

# üî∑ 7Ô∏è‚É£ Functional Capacity Comparison

| Property                    | Single Head | Multi Head |
| --------------------------- | ----------- | ---------- |
| One similarity metric       | ‚úÖ           | ‚ùå          |
| Multiple projection space   | ‚ùå           | ‚úÖ          |
| Multiple attention patterns | ‚ùå           | ‚úÖ          |
| Higher rank representation  | Limited     | Higher     |

---

# üî∑ 8Ô∏è‚É£ Geometric Interpretation

Single head:

* ‡¶è‡¶ï‡¶ü‡¶æ‡¶á angle-based similarity

Multi-head:

* ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ coordinate system
* ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ angle metric

Imagine:

Head 1 ‚Üí syntactic space
Head 2 ‚Üí semantic space
Head 3 ‚Üí positional space

‡¶è‡¶ï‡¶á embedding ‡¶•‡ßá‡¶ï‡ßá ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ geometry ‡¶§‡ßà‡¶∞‡¶ø ‡¶π‡¶ö‡ßç‡¶õ‡ßá‡•§

---

# üî∑ 9Ô∏è‚É£ Rank Argument

Attention output rank limited by attention matrix‡•§

Single-head:


$$
\mathrm{rank}(Z) \le d_k
$$

Multi-head:


Concatenation increases rank potential:

$$
\mathrm{rank}(Z) \le h \cdot d_k
$$

‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé representational capacity ‡¶¨‡¶æ‡ßú‡¶õ‡ßá‡•§

---

# üî∑ üî• Core Mathematical Insight

Multi-head attention ‚â† single-head attention with bigger dimension.

‡¶ï‡¶æ‡¶∞‡¶£:

* Separate projections
* Separate softmax distributions
* Independent attention maps

‡¶è‡¶ü‡¶æ effectively:


$$
f(x) = W_O [f_1(x),\; f_2(x),\; \dots,\; f_h(x)]
$$

‡¶è‡¶ü‡¶æ mixture-of-experts ‡¶ü‡¶æ‡¶á‡¶™ behaviour ‡¶¶‡ßá‡ßü‡•§

---

# üî∑ 10Ô∏è‚É£ Empirical Evidence

Transformer paper-‡¶è ‡¶¶‡ßá‡¶ñ‡¶æ ‡¶ó‡ßá‡¶õ‡ßá:

* Single-head performance drop ‡¶ï‡¶∞‡ßá
* Multi-head performance improves significantly

---

# üéØ Final Intuition

Single-head = ‡¶è‡¶ï ‡¶ß‡¶∞‡¶®‡ßá‡¶∞ lens ‡¶¶‡¶ø‡ßü‡ßá ‡¶¶‡ßá‡¶ñ‡¶æ
Multi-head = ‡¶Ö‡¶®‡ßá‡¶ï lens ‡¶¶‡¶ø‡ßü‡ßá ‡¶¶‡ßá‡¶ñ‡¶æ

‡¶è‡¶ï‡¶ü‡¶æ camera vs multi-camera system‡•§

---

