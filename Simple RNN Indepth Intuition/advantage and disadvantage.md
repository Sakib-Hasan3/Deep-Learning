---

## тЬЕ RNN-ржПрж░ Advantages (рж╕рзБржмрж┐ржзрж╛)

![Image](https://www.researchgate.net/publication/339316037/figure/fig1/AS%3A859736572428295%401581988580982/Schematic-of-two-different-varieties-of-RNN-sequence-to-sequence-learning-The-left-one.png)

![Image](https://images.prismic.io/encord/5205c474-6bc2-446a-b145-d3582bc2254d_image7.png?auto=compress%2Cformat)

![Image](https://www.tensorflow.org/static/text/tutorials/images/text_generation_sampling.png)

### 1я╕ПтГг Sequence Data Handle ржХрж░рждрзЗ ржкрж╛рж░рзЗ

* Text, speech, time-series, sensor data
* Input-ржПрж░ order ржмрзЛржЭрзЗ (CNN / ANN ржкрж╛рж░рзЗ ржирж╛)

ЁЯУМ ржЙржжрж╛рж╣рж░ржг:
Sentence, stock price, ECG signal

---

### 2я╕ПтГг Memory (Context Awareness)

* ржЖржЧрзЗрж░ input ржоржирзЗ рж░рж╛ржЦрзЗ (hidden state)
* Context ржзрж░рзЗ prediction ржжрзЗрзЯ

ЁЯУМ ржЙржжрж╛рж╣рж░ржг:
тАЬI am eating an ___тАЭ тЖТ **apple**

---

### 3я╕ПтГг Weight Sharing (Parameter Efficient)

* рж╕ржм time step-ржП **ржПржХржЗ weight**
* Parameter ржХржо рж▓рж╛ржЧрзЗ

ЁЯУМ рж▓рж╛ржн:
Small dataset-ржПржУ ржХрж╛ржЬ ржХрж░рзЗ

---

### 4я╕ПтГг Variable Length Input Support

* Fixed size input рж▓рж╛ржЧрзЗ ржирж╛
* Short ржмрж╛ longтАФрж╕ржм sequence ржирж┐рждрзЗ ржкрж╛рж░рзЗ

ЁЯУМ ржЙржжрж╛рж╣рж░ржг:
Different length sentences

---

### 5я╕ПтГг Time-dependent Pattern рж╢рж┐ржЦрждрзЗ ржкрж╛рж░рзЗ

* Temporal dependency capture ржХрж░рзЗ

ЁЯУМ ржЙржжрж╛рж╣рж░ржг:
Weather trend, stock movement

---

### 6я╕ПтГг Conceptually Simple

* LSTM / Transformer-ржПрж░ рждрзБрж▓ржирж╛рзЯ
* ржмрзЛржЭрж╛ ржУ implement ржХрж░рж╛ рж╕рж╣ржЬ

---

## тЭМ RNN-ржПрж░ Disadvantages (ржЕрж╕рзБржмрж┐ржзрж╛)

![Image](https://cdn.prod.website-files.com/5ef788f07804fb7d78a4127a/6245a9aca7defe61cea5ea7d_Engati-vanishing-point-problem.jpg)

![Image](https://ai-master.gitbooks.io/recurrent-neural-network/content/assets/RNN_connection.jpg)

![Image](https://miro.medium.com/1%2AcXhh5Cl60v2uRt2bxA1Thg.png)

### 1я╕ПтГг Vanishing Gradient Problem (рж╕ржмржЪрзЗрзЯрзЗ ржмрзЬ)

* Gradient ржЫрзЛржЯ рж╣рждрзЗ рж╣рждрзЗ рж╣рж╛рж░рж┐рзЯрзЗ ржпрж╛рзЯ
* Distant past рж╢рзЗржЦрж╛ ржпрж╛рзЯ ржирж╛

ЁЯУМ ржкрзНрж░ржнрж╛ржм:
Long sentence тЖТ ржнрзБрж▓ prediction

---

### 2я╕ПтГг Exploding Gradient

* Gradient ржЦрзБржм ржмрзЬ рж╣рзЯрзЗ ржпрж╛рзЯ
* Training unstable рж╣рзЯ

ЁЯУМ ржлрж▓:
Loss тЖТ NaN / тИЮ

---

### 3я╕ПтГг Long-term Dependency ржзрж░рждрзЗ ржкрж╛рж░рзЗ ржирж╛

* ржЕржирзЗржХ ржЖржЧрзЗрж░ рждржерзНржп ржнрзБрж▓рзЗ ржпрж╛рзЯ
* Context incomplete рж╣рзЯ

ЁЯУМ ржЙржжрж╛рж╣рж░ржг:
Paragraph-level meaning miss

---

### 4я╕ПтГг Sequential Training (Slow)

* Parallel ржХрж░рж╛ ржпрж╛рзЯ ржирж╛
* GPU ржкрзБрж░рзЛржкрзБрж░рж┐ ржмрзНржпржмрж╣рж╛рж░ рж╣рзЯ ржирж╛

ЁЯУМ ржлрж▓:
Large dataset тЖТ ржЦрзБржм рж╕ржорзЯ рж▓рж╛ржЧрзЗ

---

### 5я╕ПтГг Single Memory Bottleneck

* ржПржХржЯрж╛ржЗ hidden state
* Complex info ржзрж░рзЗ рж░рж╛ржЦрж╛ ржХржарж┐ржи

---

### 6я╕ПтГг Recent Input Bias

* ржирждрзБржи input ржмрзЗрж╢рж┐ ржЧрзБрж░рзБрждрзНржм ржкрж╛рзЯ
* ржкрзБрж░рзЛржирзЛ рждржерзНржп ignore рж╣рзЯ

---

### 7я╕ПтГг Not Scalable for Long Sequences

* Long audio, long document-ржП inefficient
* Production-ржП risky

---

## тЪЦя╕П Advantages vs Disadvantages (Quick Table)

| Aspect            | Advantage      | Disadvantage         |
| ----------------- | -------------- | -------------------- |
| Sequence handling | Order-aware    | Long dependency fail |
| Memory            | Context aware  | Limited memory       |
| Parameters        | Shared weights | Gradient issues      |
| Training          | Simple concept | Slow & unstable      |
| Scalability       | Small seq ok   | Long seq bad         |

---

## ЁЯза ржХржЦржи RNN ржнрж╛рж▓рзЛ?

тЬЕ ржпржЦржи:

* Sequence ржЫрзЛржЯ
* Dependency short-term
* Resource limited
* Educational / baseline model

тЭМ ржпржЦржи ржирзЯ:

* Long document
* Long audio
* Complex language task

---

## ЁЯФЪ Final Takeaway

**RNN рж╣рж▓рзЛ sequence рж╢рзЗржЦрж╛рж░ ржкрзНрж░ржержо ржзрж╛ржктАФрж╕рж╣ржЬ ржХрж┐ржирзНрждрзБ рж╕рзАржорж╛ржмржжрзНржзред
ржПржЗ рж╕рзАржорж╛ржмржжрзНржзрждрж╛ ржХрж╛ржЯрж╛рждрзЗржЗ ржПрж╕рзЗржЫрзЗ LSTM, GRU ржПржмржВ рж╢рзЗрж╖рзЗ Transformerред**

---


