<<<<<<< HEAD
---

## ğŸ”µ à¦‰à¦ªà¦°à§‡à¦° Diagram: ANN (Artificial Neural Network)

### à¦•à§€ à¦¦à§‡à¦–à¦›à§‹?

* `x1, x2, x3` â†’ à¦¸à¦¬ input **à¦à¦•à¦¸à¦¾à¦¥à§‡** ANNâ€“à¦ à¦¯à¦¾à¦šà§à¦›à§‡
* à¦à¦•à¦Ÿà¦¾à¦‡ **Hidden Layer**
* à¦¤à¦¾à¦°à¦ªà¦° **Output**

### ANN à¦•à§€à¦­à¦¾à¦¬à§‡ à¦­à¦¾à¦¬à§‡?

ğŸ§  ANN à¦¬à¦²à§‡:

> â€œà¦†à¦®à¦¿ à¦ªà§à¦°à§‹ input à¦à¦•à¦¬à¦¾à¦°à§‡ à¦¦à§‡à¦–à¦¬, à¦¤à¦¾à¦°à¦ªà¦° à¦¸à¦¿à¦¦à§à¦§à¦¾à¦¨à§à¦¤ à¦¨à§‡à¦¬â€

### à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦•à§€?

âŒ à¦•à§‹à¦¨à§‹ **memory à¦¨à§‡à¦‡**
âŒ `x1` à¦†à¦—à§‡ à¦¨à¦¾ `x3` à¦†à¦—à§‡â€”à¦à¦Ÿà¦¾ à¦¬à§‹à¦à§‡ à¦¨à¦¾
âŒ sequence / order matter à¦•à¦°à§‡ à¦¨à¦¾

ğŸ“Œ à¦¤à¦¾à¦‡ ANN à¦­à¦¾à¦²à§‹:

* Image
* Fixed-size numeric data

ğŸ“Œ à¦•à¦¿à¦¨à§à¦¤à§ à¦¦à§à¦°à§à¦¬à¦²:

* Text
* Speech
* Time-series

---

## ğŸŸ¢ à¦¨à¦¿à¦šà§‡à¦° Diagram: RNN (Recurrent Neural Network)

### à¦•à§€ à¦¦à§‡à¦–à¦›à§‹?

* `x1 â†’ x2 â†’ x3` **à¦§à¦¾à¦ªà§‡ à¦§à¦¾à¦ªà§‡** à¦¯à¦¾à¦šà§à¦›à§‡
* à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¾ stepâ€“à¦ à¦à¦•à¦‡ `[RNN]` cell
* à¦à¦•à¦Ÿà¦¾à¦° output à¦ªà¦°à§‡à¦°à¦Ÿà¦¾à¦° input-à¦à¦° à¦¸à¦¾à¦¥à§‡ à¦¯à¦¾à¦šà§à¦›à§‡ (memory)

---

## RNN à¦•à§€à¦­à¦¾à¦¬à§‡ à¦­à¦¾à¦¬à§‡?

ğŸ§  RNN à¦¬à¦²à§‡:

> â€œà¦†à¦—à§‡à¦°à¦Ÿà¦¾ à¦®à¦¨à§‡ à¦°à§‡à¦–à§‡ à¦ªà¦°à§‡à¦°à¦Ÿà¦¾ à¦¬à§à¦à¦¬â€

### à¦à¦–à¦¾à¦¨à§‡ à¦•à§€ à¦¹à¦šà§à¦›à§‡?

* `x1` à¦¢à§‹à¦•à§‡ â†’ RNN memory à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§‡
* à¦¸à§‡à¦‡ memory à¦¨à¦¿à§Ÿà§‡ `x2` à¦¢à§‹à¦•à§‡
* à¦†à¦¬à¦¾à¦° à¦¨à¦¤à§à¦¨ memory à¦¨à¦¿à§Ÿà§‡ `x3`
* à¦¶à§‡à¦·à§‡ **Output**

ğŸ“Œ à¦à¦‡ memoryâ€“à¦Ÿà¦¾à¦‡ à¦¹à¦²à§‹ **Hidden State (hâ‚œ)**

---

## ğŸ” Why RNN is called â€œRecurrentâ€?

à¦•à¦¾à¦°à¦£:

* à¦à¦•à¦‡ RNN cell
* à¦¬à¦¾à¦°à¦¬à¦¾à¦° à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦¹à§Ÿ
* à¦¨à¦¿à¦œà§‡à¦° output à¦†à¦¬à¦¾à¦° à¦¨à¦¿à¦œà§‡à¦° input à¦¹à§Ÿ

---

## Real-life Text Example ğŸ“–

Sentence:

```
à¦†à¦®à¦¿ à¦†à¦œ à¦–à§à¦¬ à¦–à§à¦¶à¦¿
```

### ANN:

* à¦¸à¦¬ à¦¶à¦¬à§à¦¦ à¦à¦•à¦¸à¦¾à¦¥à§‡ à¦¦à§‡à¦–à§‡
* order à¦¬à§‹à¦à§‡ à¦¨à¦¾ âŒ

### RNN:

* à¦†à¦®à¦¿ â†’ à¦†à¦œ â†’ à¦–à§à¦¬ â†’ à¦–à§à¦¶à¦¿
* â€œà¦–à§à¦¬â€ + â€œà¦–à§à¦¶à¦¿â€ = strong positive
  âœ… context à¦¬à§‹à¦à§‡

---

## ğŸ§  One-line Difference (Exam Gold â­)

* **ANN**: No memory, no sequence
* **RNN**: Has memory, understands sequence

---

## âœï¸ Exam-ready Line

> â€œRNN differs from ANN by introducing a recurrent connection which allows the network to retain past information and process sequential data.â€

---


=======
---

## ğŸ”µ à¦‰à¦ªà¦°à§‡à¦° Diagram: ANN (Artificial Neural Network)

### à¦•à§€ à¦¦à§‡à¦–à¦›à§‹?

* `x1, x2, x3` â†’ à¦¸à¦¬ input **à¦à¦•à¦¸à¦¾à¦¥à§‡** ANNâ€“à¦ à¦¯à¦¾à¦šà§à¦›à§‡
* à¦à¦•à¦Ÿà¦¾à¦‡ **Hidden Layer**
* à¦¤à¦¾à¦°à¦ªà¦° **Output**

### ANN à¦•à§€à¦­à¦¾à¦¬à§‡ à¦­à¦¾à¦¬à§‡?

ğŸ§  ANN à¦¬à¦²à§‡:

> â€œà¦†à¦®à¦¿ à¦ªà§à¦°à§‹ input à¦à¦•à¦¬à¦¾à¦°à§‡ à¦¦à§‡à¦–à¦¬, à¦¤à¦¾à¦°à¦ªà¦° à¦¸à¦¿à¦¦à§à¦§à¦¾à¦¨à§à¦¤ à¦¨à§‡à¦¬â€

### à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦•à§€?

âŒ à¦•à§‹à¦¨à§‹ **memory à¦¨à§‡à¦‡**
âŒ `x1` à¦†à¦—à§‡ à¦¨à¦¾ `x3` à¦†à¦—à§‡â€”à¦à¦Ÿà¦¾ à¦¬à§‹à¦à§‡ à¦¨à¦¾
âŒ sequence / order matter à¦•à¦°à§‡ à¦¨à¦¾

ğŸ“Œ à¦¤à¦¾à¦‡ ANN à¦­à¦¾à¦²à§‹:

* Image
* Fixed-size numeric data

ğŸ“Œ à¦•à¦¿à¦¨à§à¦¤à§ à¦¦à§à¦°à§à¦¬à¦²:

* Text
* Speech
* Time-series

---

## ğŸŸ¢ à¦¨à¦¿à¦šà§‡à¦° Diagram: RNN (Recurrent Neural Network)

### à¦•à§€ à¦¦à§‡à¦–à¦›à§‹?

* `x1 â†’ x2 â†’ x3` **à¦§à¦¾à¦ªà§‡ à¦§à¦¾à¦ªà§‡** à¦¯à¦¾à¦šà§à¦›à§‡
* à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¾ stepâ€“à¦ à¦à¦•à¦‡ `[RNN]` cell
* à¦à¦•à¦Ÿà¦¾à¦° output à¦ªà¦°à§‡à¦°à¦Ÿà¦¾à¦° input-à¦à¦° à¦¸à¦¾à¦¥à§‡ à¦¯à¦¾à¦šà§à¦›à§‡ (memory)

---

## RNN à¦•à§€à¦­à¦¾à¦¬à§‡ à¦­à¦¾à¦¬à§‡?

ğŸ§  RNN à¦¬à¦²à§‡:

> â€œà¦†à¦—à§‡à¦°à¦Ÿà¦¾ à¦®à¦¨à§‡ à¦°à§‡à¦–à§‡ à¦ªà¦°à§‡à¦°à¦Ÿà¦¾ à¦¬à§à¦à¦¬â€

### à¦à¦–à¦¾à¦¨à§‡ à¦•à§€ à¦¹à¦šà§à¦›à§‡?

* `x1` à¦¢à§‹à¦•à§‡ â†’ RNN memory à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§‡
* à¦¸à§‡à¦‡ memory à¦¨à¦¿à§Ÿà§‡ `x2` à¦¢à§‹à¦•à§‡
* à¦†à¦¬à¦¾à¦° à¦¨à¦¤à§à¦¨ memory à¦¨à¦¿à§Ÿà§‡ `x3`
* à¦¶à§‡à¦·à§‡ **Output**

ğŸ“Œ à¦à¦‡ memoryâ€“à¦Ÿà¦¾à¦‡ à¦¹à¦²à§‹ **Hidden State (hâ‚œ)**

---

## ğŸ” Why RNN is called â€œRecurrentâ€?

à¦•à¦¾à¦°à¦£:

* à¦à¦•à¦‡ RNN cell
* à¦¬à¦¾à¦°à¦¬à¦¾à¦° à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦¹à§Ÿ
* à¦¨à¦¿à¦œà§‡à¦° output à¦†à¦¬à¦¾à¦° à¦¨à¦¿à¦œà§‡à¦° input à¦¹à§Ÿ

---

## Real-life Text Example ğŸ“–

Sentence:

```
à¦†à¦®à¦¿ à¦†à¦œ à¦–à§à¦¬ à¦–à§à¦¶à¦¿
```

### ANN:

* à¦¸à¦¬ à¦¶à¦¬à§à¦¦ à¦à¦•à¦¸à¦¾à¦¥à§‡ à¦¦à§‡à¦–à§‡
* order à¦¬à§‹à¦à§‡ à¦¨à¦¾ âŒ

### RNN:

* à¦†à¦®à¦¿ â†’ à¦†à¦œ â†’ à¦–à§à¦¬ â†’ à¦–à§à¦¶à¦¿
* â€œà¦–à§à¦¬â€ + â€œà¦–à§à¦¶à¦¿â€ = strong positive
  âœ… context à¦¬à§‹à¦à§‡

---

## ğŸ§  One-line Difference (Exam Gold â­)

* **ANN**: No memory, no sequence
* **RNN**: Has memory, understands sequence

---

## âœï¸ Exam-ready Line

> â€œRNN differs from ANN by introducing a recurrent connection which allows the network to retain past information and process sequential data.â€

---


>>>>>>> f45ebbad1686e699afe9932c4175eeff501d254b
