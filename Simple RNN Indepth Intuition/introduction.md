---

## RNN ржХрзА?

**RNN** ржПржоржи ржПржХ ржзрж░ржирзЗрж░ Neural Network ржпрж╛ **sequence data** ржирж┐рзЯрзЗ ржХрж╛ржЬ ржХрж░рзЗред

ЁЯУМ Sequence ржорж╛ржирзЗ

* ржмрж╛ржХрзНржп (рж╢ржмрзНржжрзЗрж░ рж╕рж┐рж░рж┐ржЬ)
* ржЯрж╛ржЗржо рж╕рж┐рж░рж┐ржЬ
* Speech
* Text

ЁЯСЙ RNN ржЖржЧрзЗрж░ рждржерзНржп **ржоржирзЗ рж░рзЗржЦрзЗ** ржкрж░рзЗрж░ ржЗржиржкрзБржЯ ржмрзБржЭрждрзЗ ржкрж╛рж░рзЗред

---

## Simple Neural Network vs RNN

### ЁЯФ╣ Normal Neural Network

* ржкрзНрж░рждрж┐ржЯрж╛ input ржЖрж▓рж╛ржжрж╛
* ржХрзЛржирзЛ memory ржирзЗржЗ

### ЁЯФ╣ RNN

* ржЖржЧрзЗрж░ output / state ржоржирзЗ рж░рж╛ржЦрзЗ
* sequence ржмрзБржЭрждрзЗ ржкрж╛рж░рзЗ

---

## RNN ржХрзАржнрж╛ржмрзЗ ржХрж╛ржЬ ржХрж░рзЗ?

ржПржХржЯрж╛ sentence ржзрж░рзЛ:

```
ржЖржорж┐ ржЖржЬ рж╕рзНржХрзБрж▓рзЗ ржпрж╛ржЗ
```

RNN ржПржХржмрж╛рж░рзЗ ржкрзБрж░рзЛ ржмрж╛ржХрзНржп ржирзЗрзЯ ржирж╛ тЭМ
ЁЯСЙ рж╢ржмрзНржж ржзрж░рзЗ ржзрж░рзЗ ржирзЗрзЯ:

```
ржЖржорж┐ тЖТ ржЖржЬ тЖТ рж╕рзНржХрзБрж▓рзЗ тЖТ ржпрж╛ржЗ
```

ржкрзНрж░рждрж┐ржЯрж╛ ржзрж╛ржкрзЗ RNN ржжрзБржЗржЯрж╛ ржЬрж┐ржирж┐рж╕ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ:

* ржмрж░рзНрждржорж╛ржи input (xтВЬ)
* ржЖржЧрзЗрж░ hidden state (hтВЬтВЛтВБ)

---

## Simple RNN ржПрж░ Formula (Basic)

ржкрзНрж░рждрж┐ time step ржП:

[
h_t = \tanh(W_h h_{t-1} + W_x x_t + b)
]

* (x_t) = ржмрж░рзНрждржорж╛ржи рж╢ржмрзНржж
* (h_{t-1}) = ржЖржЧрзЗрж░ memory
* (h_t) = ржирждрзБржи memory
* (W) = weight
* tanh = activation function

---

## Visual Idea ЁЯза

```
x1 тЖТ [RNN] тЖТ h1
x2 тЖТ [RNN] тЖТ h2
x3 тЖТ [RNN] тЖТ h3
```

ЁЯСЙ h2 рждрзИрж░рж┐ рж╣рзЯ h1 ржоржирзЗ рж░рзЗржЦрзЗ
ЁЯСЙ h3 рждрзИрж░рж┐ рж╣рзЯ h2 ржоржирзЗ рж░рзЗржЦрзЗ

---

## Simple Example (Sentiment)

Sentence:

```
"ржПржЗ рж╕рж┐ржирзЗржорж╛ржЯрж╛ ржЦрзБржм ржнрж╛рж▓рзЛ"
```

* "ржнрж╛рж▓рзЛ" ржЖрж╕рж╛рж░ ржЖржЧрзЗ RNN ржЬрж╛ржирзЗ
* ржЖржЧрзЗ "ржЦрзБржм" ржПрж╕рзЗржЫрзЗ
  тЮбя╕П рждрж╛ржЗ sentiment positive ржмрзБржЭрждрзЗ ржкрж╛рж░рзЗ

---

## Simple RNN Code (Keras / TensorFlow)

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense

model = Sequential()
model.add(SimpleRNN(32, input_shape=(10, 1)))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()
```

ЁЯУМ ржПржЦрж╛ржирзЗ

* `32` = hidden units
* `10` = sequence length
* `1` = feature per step

---

## RNN ржХрзЛржерж╛рзЯ ржмрзНржпржмрж╣рж╛рж░ рж╣рзЯ?

* Text classification
* Language modeling
* Simple chatbot
* Speech recognition

---

## RNN ржПрж░ рж╕ржорж╕рзНржпрж╛ тЭМ

* Long sentence ржП ржЖржЧрзЗрж░ рждржерзНржп ржнрзБрж▓рзЗ ржпрж╛рзЯ
* Vanishing gradient problem

ЁЯСЙ ржПржЬржирзНржпржЗ ржкрж░рзЗ ржПрж╕рзЗржЫрзЗ
тЬЕ **LSTM**
тЬЕ **GRU**

---

## ржХржЦржи Simple RNN ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржмрзЗ?

тЬФ ржЫрзЛржЯ sequence
тЬФ learning purpose
тЬФ basic NLP understanding

тЭМ ржмрзЬ paragraph / long context тЖТ LSTM / Transformer ржнрж╛рж▓рзЛ

---

