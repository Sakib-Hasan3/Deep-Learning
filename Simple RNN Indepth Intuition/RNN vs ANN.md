---

## 1я╕ПтГг ANN (Artificial Neural Network) ржХрзА?

### ЁЯз▒ ANN Architecture

ANN рж╕рж╛ржзрж╛рж░ржгржд **Feedforward Network**:

```
Input тЖТ Hidden Layer тЖТ Output
```

ЁЯУМ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп

* ржПржХржмрж╛рж░рзЗ ржкрзБрж░рзЛ input ржирзЗрзЯ
* ржХрзЛржирзЛ **memory ржирзЗржЗ**
* ржЖржЧрзЗрж░ input ржоржирзЗ рж░рж╛ржЦрзЗ ржирж╛

### ЁЯФН ANN ржХрзАржнрж╛ржмрзЗ ржХрж╛ржЬ ржХрж░рзЗ?

ржзрж░рзЛ ржЗржиржкрзБржЯ:

```
[5, 7, 3]
```

ANN ржПржХрж╕рж╛ржерзЗ рж╕ржм ржЗржиржкрзБржЯ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рзЗ
ЁЯСЙ Output ржжрзЗрзЯ
ЁЯСЙ ржПрж░ржкрж░ рж╕ржм ржнрзБрж▓рзЗ ржпрж╛рзЯ ЁЯШД

---

## ANN ржХрзЛржерж╛рзЯ ржнрж╛рж▓рзЛ?

тЬФ Image classification
тЬФ Tabular data
тЬФ Fixed-size input

тЭМ Sequence data (text, speech)

---

## 2я╕ПтГг RNN (Recurrent Neural Network) ржХрзА?

### ЁЯФД RNN Architecture

RNN ржПрж░ ржнрж┐рждрж░рзЗ ржПржХржЯрж╛ **loop** ржерж╛ржХрзЗ ЁЯФБ

```
xтВБ тЖТ [RNN] тЖТ hтВБ
xтВВ тЖТ [RNN] тЖТ hтВВ
xтВГ тЖТ [RNN] тЖТ hтВГ
```

ЁЯУМ ржПржЦрж╛ржирзЗ

* hтВЬ = hidden state (memory)
* hтВЬ ржЖржЧрзЗрж░ hтВЬтВЛтВБ ржоржирзЗ рж░рж╛ржЦрзЗ

---

## RNN Architecture (Inside View)

ржПржХржЯрж╛ time step ржП:

```
      h(t-1)
        тЖС
x(t) тЖТ [RNN Cell] тЖТ h(t)
```

ЁЯСЙ ржмрж░рзНрждржорж╛ржи input + ржЖржЧрзЗрж░ memory
ЁЯСЙ ржирждрзБржи memory рждрзИрж░рж┐

---

## RNN ржПрж░ Core Equation

[
h_t = \tanh(W_x x_t + W_h h_{t-1} + b)
]

ЁЯСЙ ржПржЯрж╛ржХрзЗржЗ RNN тАЬmemoryтАЭ ржмрж▓рж╛ рж╣рзЯ

---

## Real-life Example ЁЯза

### Sentence:

```
"ржЖржЬ ржЖржХрж╛рж╢ ржЦрзБржм рж╕рзБржирзНржжрж░"
```

### ANN рж╣рж▓рзЗ:

* "ржЖржЬ", "ржЖржХрж╛рж╢", "ржЦрзБржм", "рж╕рзБржирзНржжрж░" ржПржХрж╕рж╛ржерзЗ ржжрзЗржЦрзЗ
* word order ржмрзБржЭрждрзЗ ржкрж╛рж░рзЗ ржирж╛

### RNN рж╣рж▓рзЗ:

* ржЖржЬ тЖТ ржЖржХрж╛рж╢ тЖТ ржЦрзБржм тЖТ рж╕рзБржирзНржжрж░
* sequence ржзрж░рзЗ ржзрж░рзЗ ржмрзБржЭрзЗ
* "ржЦрзБржм рж╕рзБржирзНржжрж░" context ржзрж░рзЗ рж░рж╛ржЦрзЗ

---

## 3я╕ПтГг RNN vs ANN (Side-by-Side)

| Feature       | ANN        | RNN           |
| ------------- | ---------- | ------------- |
| Input type    | Fixed size | Sequence      |
| Memory        | тЭМ ржирзЗржЗ      | тЬЕ ржЖржЫрзЗ         |
| Order matters | тЭМ ржирж╛       | тЬЕ рж╣рзНржпрж╛ржБ       |
| Same weights  | тЭМ          | тЬЕ (time-wise) |
| Text / Speech | тЭМ ржжрзБрж░рзНржмрж▓   | тЬЕ ржнрж╛рж▓рзЛ        |

---

## Architecture Difference (Conceptually)

### ANN

```
x1   x2   x3
 |    |    |
 v    v    v
[  Hidden Layer ]
        |
      Output
```

### RNN (Unrolled)

```
x1 тЖТ h1 тЖТ y1
x2 тЖТ h2 тЖТ y2
x3 тЖТ h3 тЖТ y3
```

ЁЯСЙ ржПржЦрж╛ржирзЗ **same RNN cell ржмрж╛рж░ржмрж╛рж░ reuse рж╣рзЯ**

---

## Key Concept: Weight Sharing

RNNтАУржП:

* ржПржХржЗ weight ржкрзНрж░рждрж┐ржЯрж╛ time step ржП ржмрзНржпржмрж╣рж╛рж░ рж╣рзЯ
* ANNтАУржП ржкрзНрж░рждрж┐ржЯрж╛ layer ржЖрж▓рж╛ржжрж╛ weight

---

## ржХрзЗржи ANN sequence ржП fail ржХрж░рзЗ?

Sentence:

```
"рж╕рзЗ ржЖржорж╛ржХрзЗ ржорж╛рж░рзЗржирж┐"
```

ANN рж╢рзБржзрзБ рж╢ржмрзНржж ржжрзЗржЦрзЗ
тЭМ context + order miss ржХрж░рзЗ

RNN ржЬрж╛ржирзЗ:

* "ржорж╛рж░рзЗржирж┐" рж╢рзЗрж╖рзЗ ржПрж╕рзЗржЫрзЗ
* negation ржмрзБржЭрждрзЗ ржкрж╛рж░рзЗ

---

## RNN ржПрж░ Limitation

* Long sentence тЖТ memory fade
* Vanishing gradient

ЁЯСЙ Solution:

* **LSTM**
* **GRU**
* **Transformer**

---

## Quick Intuition Summary ЁЯзй

* ANN = тАЬржПржХржмрж╛рж░рзЗ ржжрзЗржЦрзЗ ржмрж┐ржЪрж╛рж░тАЭ
* RNN = тАЬржПржХржЯрж╛рж░ ржкрж░ ржПржХржЯрж╛ ржжрзЗржЦрзЗ ржоржирзЗ рж░рзЗржЦрзЗ ржмрж┐ржЪрж╛рж░тАЭ

---


